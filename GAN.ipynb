{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "io7suaaTnSM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17UZTu0OnXW7",
        "colab_type": "text"
      },
      "source": [
        "## Baseline W-DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTBpdiWonWtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (64,64,3)\n",
        "latent_dim = 100\n",
        "\n",
        "n_critic = 5\n",
        "clip_value = 0.01\n",
        "optimizer = RMSprop(lr=0.00005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iF1kWlAoAf8",
        "colab_type": "text"
      },
      "source": [
        "### Critic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_rfpoayoAAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.summary()\n",
        "  \n",
        "  img = Input(shape=img_shape)\n",
        "  valid = model(img)\n",
        "  \n",
        "  \n",
        "  return Model(img, valid)\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mARjIEYMn5FW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "440a3fea-28d3-459a-95c3-149c8cabf3c7"
      },
      "source": [
        "discriminator()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 17, 17, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 9, 9, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 9, 9, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 9, 9, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 10369     \n",
            "=================================================================\n",
            "Total params: 108,705\n",
            "Trainable params: 108,257\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fb472edcc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xedPZ8rBBgkL",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOU2V7P2o8tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(4096, activation=\"relu\", input_dim=latent_dim))\n",
        "  model.add(Reshape((4, 4, 256)))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(3, kernel_size=3, padding=\"same\")) # 3 rgb channels\n",
        "  model.add(Activation(\"tanh\"))\n",
        "\n",
        "  model.summary()\n",
        "  \n",
        "  noise = Input(shape=(latent_dim,))\n",
        "  img = model(noise)\n",
        "  return Model(noise, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvAwcoBupVcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "c209417c-db13-429e-d4ed-1451334e713b"
      },
      "source": [
        "generator()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 4096)              413696    \n",
            "_________________________________________________________________\n",
            "reshape_10 (Reshape)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_25 (UpSampling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 8, 8, 128)         295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_26 (UpSampling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_27 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_28 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 64, 64, 3)         867       \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 802,755\n",
            "Trainable params: 802,307\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fb470cb7fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qded8R8XzwZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wloss(y_true, y_pred):\n",
        "  return K.mean(y_true*y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3xgibfa06n3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "c1ca448d-6c95-4516-dfe6-3cee2a34b423"
      },
      "source": [
        "d = discriminator()\n",
        "g = generator()\n",
        "\n",
        "\n",
        "d.compile(loss=wloss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = g(z)\n",
        "\n",
        "d.trainable = False\n",
        "valid = d(img)\n",
        "\n",
        "GAN = Model(z, valid)\n",
        "GAN.compile(loss=wloss, optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 17, 17, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 9, 9, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 9, 9, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 9, 9, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 10369     \n",
            "=================================================================\n",
            "Total params: 108,705\n",
            "Trainable params: 108,257\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 4096)              413696    \n",
            "_________________________________________________________________\n",
            "reshape_12 (Reshape)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_33 (UpSampling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 8, 8, 128)         295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_34 (UpSampling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_35 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_36 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 64, 64, 3)         867       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 802,755\n",
            "Trainable params: 802,307\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnx9c3Zr4rD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images(epoch):\n",
        "  r,c = 5,5\n",
        "  noise = np.random.normal(0,1, (r*c, latent_dim))\n",
        "  gen_imgs = g.predict(noise)\n",
        "  \n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "  \n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "      axs[i,j].axis('off')\n",
        "      cnt += 1\n",
        "  fig.savefig(\"gan_%d.png\" % epoch)\n",
        "  plt.close()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJDSG-Qp1lhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(GAN, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTc0c2QMrVkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs=500, batch_size=128, sample_interval=50):\n",
        "  \n",
        "  valid = -np.ones((batch_size, 1)) # negative since using tanh\n",
        "  fake = np.ones((batch_size, 1))\n",
        "  generator = g\n",
        "  discriminator = d\n",
        "  \n",
        " \n",
        "  datagen_dfc = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True)\n",
        "  X_train_gen = datagen_dfc.flow_from_directory(train_path,\n",
        "        target_size=(64,64), batch_size=batch_size,\n",
        "        class_mode=None, color_mode=\"rgb\")\n",
        "  for epoch in range(epochs):\n",
        "    print(epoch)\n",
        "    for _ in range(n_critic):\n",
        "    \n",
        "      # Train discriminator\n",
        "      \n",
        "      \n",
        "      imgs = next(X_train_gen)\n",
        "      \n",
        "      noise = np.random.normal(0,1, (batch_size, latent_dim))\n",
        "      \n",
        "      # generates new image\n",
        "      gen_imgs = generator.predict(noise)\n",
        "      \n",
        "      d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(imgs, fake)\n",
        "      d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "      \n",
        "      for l in discriminator.layers:\n",
        "        weights = l.get_weights()\n",
        "        weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
        "        l.set_weights(weights)\n",
        "    # train generator\n",
        "    g_loss = GAN.train_on_batch(noise, valid)\n",
        "    print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
        "    if epoch % sample_interval == 0:\n",
        "      sample_images(epoch)\n",
        "   \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhJZSENnzHt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a8d05944-db89-4ad3-97e0-b8277e0ae5e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strCE8L1ByUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f1ce78c-6374-42a1-d649-4373677562fd"
      },
      "source": [
        "train_path = \"/content/drive/My Drive/train/\"\n",
        "test_path = \"/content/drive/My Drive/test/\"\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17441 images belonging to 1 classes.\n",
            "Found 867 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRhiKr3rDLyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "31f23da3-c3bd-442a-9b46-cf85c2fafdba"
      },
      "source": [
        "train(epochs=4000)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17441 images belonging to 1 classes.\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.999848] [G loss: 1.000347]\n",
            "1\n",
            "1 [D loss: 0.999855] [G loss: 1.000358]\n",
            "2\n",
            "2 [D loss: 0.999866] [G loss: 1.000369]\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-81e030841ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-1f17899f5cfb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    224\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}